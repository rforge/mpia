LSA ist eine Methode um semantisch äquivalente, aber unterschiedlich geschriebene Wörter mit Hilfe einer mathematischen Methode zu identifizieren. In einem ersten Schritt wird eine „Textmatrix“ (Dokument/Wort-Matrix) erstellt, welche in den Zeilen jedes der einzelnen Worte  der zu prüfenden Texte enthält und in den Spalten die Textpassage, Dokument bzw. den Kontext. Jede Zelle enthält vorerst die Anzahl (frequency) mit der es in dem entsprechenden zugeordneten Text auftritt. Weiters wird für jedes Wort ein gewichteter Wert berechnet und zwar mit Hilfe einer Funktion, die sowohl die Relevanz des Wortes in dem Dokument als auch den Grad des Informationsgehalts des Wortes im allgemeinen enthält. Als nächster Schritt wird die Singular Value Decomposition (SVD) durchgeführt. Diese Methode ist eine Form der Faktor-Analyse, mit Hilfe derer die Wort/Dokument-Matrix (X) in drei andere Matrizen gespalten wird, nämlich die orthogonalen Matrizen W und P und in die Diagonale S. Eine Matrize beschreibt die Original-Zeileneinträge als Vektoren der orthogonalen Faktorwerte, die zweite die Spalteneinträge auf dieselbe Art und Weise. Die dritte, die Diagonale enthält die Skalenwerte (singular values) die durch Multiplikation wieder die Original-Matrixwerte ergeben. Nach Neuordnung dieser Werte und Umsortierung der ursprünglichen Matrizen wird die ursprüngliche Matrize X in einen geringer dimensionalen Raum durch das Nullsetzen aller Werte außer dem höchsten projeziert. Die Ähnlichkeit zweier Worte wird durch die Position der Wort-Vektoren in der Matrize im reduziert-dimensionalen Raum bestimmt. (z.B.: durch den Winkel zwischen den Vektoren).

