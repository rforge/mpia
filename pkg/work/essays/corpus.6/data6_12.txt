LSA ist eine vollautomatische mathematisch-statistische Methode zur Identifizierung semantisch gleichwertiger, aber verschieden geschriebener Wörter. Zunächst wird der zu untersuchende Text als Matrix dargestellt, in der jede Reihe für ein einzigartiges Wort und jede Spalte für eine Textpassage oder den Kontext steht. Jede Zelle enthält nun die Häufigkeit – frequency – eines Wortes einer Reihe mit der es in der durch die Spalten repräsentierten Textpassage vorkommt. In Folge wird die Zellenhäufigkeit mittels einer Funktion gewichtet, die die Relevanz und den Informationsgehalt des Wortes veranschaulicht. Die Wort-Text-Matrix wird in einem weiteren Verfahrensteil mit Hilfe der „Singular Value Decomposition“ (SVD) – Methode, einer Form der Faktor-Analyse, in drei neue Matrizen gespalten. Diese Matrizen enthalten als Vektoren dargestellt die eigentlichen Zeilen-Spalteneinträge und die „singular values“ – die Skalenwerte. Darauf folgend wird die Ausgangsmatrix mit Hilfe des Nullsetzens aller Werte, mit Ausnahme des Höchsten in einen kleiner-dimensionalen Raum projiziert. Vorab werden die Werte noch neu geordnet und neu sortiert. Schließlich lässt die Stellung der Vektoren im kleindimensionalen Raum Rückschlüsse auf die Ähnlichkeit der Ursprungsinhalte zu.

