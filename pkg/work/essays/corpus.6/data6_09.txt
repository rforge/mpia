Der Titel LSA (Latent Semantic Analysis) deutet bereits darauf hin, dass es sich um eine Methode handelt, die in der Lage ist, die latente semantische Struktur zwischen Wörtern aufzudecken. Latente Semantik bedeutet verborgene Information. Es ist eine Methode, die durch mathematische/statistische Techniken, sich folgernde, zusammenhangsbezogene Wörter in Textpassagen finden soll. Der erste Schritt ist einen Text in einer Matrix  darzustellen. Hierbei gilt, dass jede einzelne Reihe für ein bestimmtes Wort und jede Spalte für eine Textpassage reserviert ist. Der nächste Schritt ist die Singulärwertzerlegung (SVD). Dabei wird eine rechteckige Matrix, in drei andere Matrizen zerlegt. Dahergehend, dass man viele Wörter in die Matrix miteinbezieht, wird diese auch sehr groß ausfallen. Die erste Matrix beschreibt die Wörter, die zweite die Passagen und die dritte ist eine Diagonalmatrix. Da beim Multiplizieren von Matrizen Produkte der Einträge addiert werden, und die Reihenfolge bei der Addition egal ist, können Zeilen und Spalten der Diagonalmatrix vertauscht werden, solange auch die entsprechenden Spalten von den beiden anderen Matrizen vertauscht werden. Dadurch kann erreicht werden, dass die Werte auf der Diagonalmatrix, welche Singulärwerte heißen, absteigend geordnet sind. Dadurch kommt man zu kleineren Faktoren, die nicht berücksichtigt werden müssen. Durch dieses Verfahren findet eine Annäherung statt, welche man auch als Dimensionsreduktion bezeichnen kann, wobei man hofft, dass die wichtigen Wörter übrigbleiben. Die Methode liefert ein Maß für die Ähnlichkeit von Wörtern.

