d$dtm
d$space
d = Domain(name="test")#
evidence = VectorSource( c("abc abc def", "def ghi", "ghi abc, lmno", "lmno abc wxyz") )#
d$corpus(evidence)#
d$spacify()#
#
p = Performance(text="abc def ghi", domain=d, purpose="demo", name="demo")#
terms(p)
d$dtm
as.matrix(d$dtm)
?dgC?dgCMatrix-class?dgCMatrix-class?dgCMatrix-class
class(d$dtm)
class(d$dtm) = "dgCMatrix"
x
evidence
x = evidence
tm = Corpus(x, readerControl=list(reader=readPlain, language="en", load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE))#
      tm = tm_map(tm, tolower)#
      # save full dictionary for stem completion#
      dict = Terms(DocumentTermMatrix( tm, control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)))#
      # stemming#
      tm = tm_map(tm, stemDocument, language="en")#
      dtm = TermDocumentMatrix(tm, control = list(#
         removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
         minWordLength = 3, bounds = list(global=c(1,Inf))#
      ))#
#
      # stem completion#
      sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
      sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
      rownames(dtm) = sc#
      if (any(duplicated(rownames(dtm)))) {#
          dupes = which(duplicated(rownames(dtm)))#
          for (i in dupes) {#
              hits = which(sc == sc[i])#
              target = hits[ which(! hits %in% which(duplicated(sc))) ]#
              replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
              rownames(replvec) = sc[target]#
              dtm[ target,1:length(replvec) ] = replvec#
          }#
          dtm = dtm[!duplicated(rownames(dtm)),]#
      }#
      if (any(rownames(dtm) == "")) {#
          cat("removing empty ones")#
          dtm = dtm[-(which(rownames(dtm) == "")), ]#
      }
class(dtm)
dtm
sum(dtm*dtm)
1/0
log(-)
log(0)
log(-1)
dmgr$get("madeupname")
q()
library(mpia)
a = proc.time()#
#
essays.content = read.csv2(file="~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.content.csv", stringsAsFactors=FALSE)#
#
tm = Corpus(#
        VectorSource(essays.content[,2]),#
        readerControl=list(#
            reader=readPlain, language="de",#
            load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE#
        )#
    )#
#
tm = tm_map(tm, function(e) return(gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", e)))#
tm = tm_map(tm, tolower)#
#
# save full dictionary for stem completion#
dict = Terms(DocumentTermMatrix(#
	tm,#
	control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)#
))#
#
length(dict)#
#
# stemming#
tm = tm_map(tm, stemDocument, language="ger")#
dtm = TermDocumentMatrix(tm, control = list(#
    removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
    minWordLength = 3, bounds = list(global=c(1,Inf))#
))#
#
dim(dtm)#
#
# stem completion#
sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
#
rownames(dtm) = sc#
if (any(duplicated(rownames(dtm)))) {#
    dupes = which(duplicated(rownames(dtm)))#
    for (i in dupes) {#
        #cat(paste("removing dupe for ", sc[i], "\n", sep=""))#
		hits = which(sc == sc[i])#
        target = hits[ which(! hits %in% which(duplicated(sc))) ]#
        replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
        rownames(replvec) = sc[target]#
        dtm[ target,1:length(replvec) ] = replvec#
    }#
    dtm = dtm[!duplicated(rownames(dtm)),]#
}#
class(dtm) = c("TermDocumentMatrix", class(dtm))#
#
dim(dtm)#
#
if (any(rownames(dtm) == "")) {#
    cat("removing empty ones")#
    dtm = dtm[-(which(rownames(dtm) == "")), ]#
}#
#
dim(dtm)#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# check for outliers: plot freq dist with chosen upper/lower threshold window#
#
#freqs = rowSums(as.matrix(dtm))#
#
#plot(sort(freqs, dec=T), type="l", log="xy", ylab="frequency (log-scaled)", xlab="terms (log-scaled)")#
#
#greater10 = length(which(freqs > ncol(dtm)/10))#
#greater25 = length(which(freqs > ncol(dtm)/4))#
#greater50 = length(which(freqs > ncol(dtm)/2))#
#
#justonce = length(which(freqs>1))#
#justtwice = length(which(freqs>2))#
#just5 = length(which(freqs>5))#
#
#rect(greater25,ncol(dtm)/4, justtwice, 2, lty="dotted", col=rgb(0.3,0.3,0.3, alpha=0.1))#
#
#text(greater10+20, 10+ncol(dtm)/10, paste(greater10, "> 10%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/10, lty="dashed", col="darkgreen")#
#
#text(greater25+15, 20+ncol(dtm)/4, paste(greater25, "> 25%", sep=" "), col="darkgreen", cex=0.7, font=2)#
#abline(h=ncol(dtm)/4, lty="dashed", col="darkgreen")#
#
#text(greater50+2, 20+ncol(dtm)/2, paste(greater50, "> 50%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/2, lty="dashed", col="darkgreen")#
#
#abline(v=justonce, lty="dotted", col="darkred")#
#text(justonce-400, 1, paste(justonce,">1",sep=" "), col="darkred", cex=0.7)#
#
#abline(v=justtwice, lty="dotted", col="darkred")#
#text(justtwice-300, 2, paste(justtwice,">2",sep=" "), col="darkred", cex=0.7, font=2)#
#
#abline(v=just5, lty="dotted", col="darkred")#
#text(just5-50, 4, paste(just5,">5",sep=" "), col="darkred", cex=0.7)#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# filtering by threshold#
#
lower = which(freqs>1)#
dtm = dtm[lower,]#
#
freqs = rowSums(as.matrix(dtm))#
upper = which(freqs < ncol(dtm)/4)#
dtm = dtm[upper,]#
#
empty = as.integer( which(colSums(as.matrix(dtm))==0) )#
dtm = dtm[,-(empty)]#
#
# t2t size:#
nrow(dtm)^2 * 8 / 1024 / 1024#
# 15.97449 MB#
#
dtm = as.matrix(dtm)#
#
proc.time() - a
a = proc.time()#
space = lsa(dtm, dims=dimcalc_raw())#
proc.time()-a
# superfast#
tr = sum(dtm*dtm)#
tr#
# 20887#
#
tr * 0.8#
# 16709.6#
#
#save(space, file="~/Documents/mpia/space-essaysonly-raw.RData")#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# find ideal truncation (recalc tr or use from above)#
#
# check if svd was calculated with enough dimensions (here: true, since dimcalc_raw() was used)#
if ( ! tr*0.8<sum(space$sk^2) ) stop("svd has too few factors!")#
#
# find cutoff#
threshold = tr * 0.8#
r = 0#
for (i in 1:length(space$sk)) {#
    r = r + (space$sk[i]^2)#
    if (r >= threshold) {#
        cutoff = i-1#
        break()#
    }#
}#
#
cutoff
class(dtm) = "matrix"#
dtm = Matrix(dtm)#
#
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
class(dtm)
nrow(dtm)
source("~/Documents/werkstatt/lsa-package/lsa/pkg/lsa/R/svdlibc.R")
class(dtm) = "matrix"#
dtm = Matrix(dtm)#
#
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
1 - 1.771 / 4.699
cutoff
q()
a = proc.time()#
#
essays.content = read.csv2(file="~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.content.csv", stringsAsFactors=FALSE)#
#
tm = Corpus(#
        VectorSource(essays.content[,2]),#
        readerControl=list(#
            reader=readPlain, language="de",#
            load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE#
        )#
    )#
#
tm = tm_map(tm, function(e) return(gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", e)))#
tm = tm_map(tm, tolower)#
#
# save full dictionary for stem completion#
dict = Terms(DocumentTermMatrix(#
	tm,#
	control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)#
))#
#
length(dict)#
#
# stemming#
tm = tm_map(tm, stemDocument, language="ger")#
dtm = TermDocumentMatrix(tm, control = list(#
    removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
    minWordLength = 3, bounds = list(global=c(1,Inf))#
))#
#
dim(dtm)#
#
# stem completion#
sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
#
rownames(dtm) = sc#
if (any(duplicated(rownames(dtm)))) {#
    dupes = which(duplicated(rownames(dtm)))#
    for (i in dupes) {#
        #cat(paste("removing dupe for ", sc[i], "\n", sep=""))#
		hits = which(sc == sc[i])#
        target = hits[ which(! hits %in% which(duplicated(sc))) ]#
        replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
        rownames(replvec) = sc[target]#
        dtm[ target,1:length(replvec) ] = replvec#
    }#
    dtm = dtm[!duplicated(rownames(dtm)),]#
}#
class(dtm) = c("TermDocumentMatrix", class(dtm))#
#
dim(dtm)#
#
if (any(rownames(dtm) == "")) {#
    cat("removing empty ones")#
    dtm = dtm[-(which(rownames(dtm) == "")), ]#
}#
#
dim(dtm)#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# check for outliers: plot freq dist with chosen upper/lower threshold window#
# commented for performance benchmark: just uncomment!#
#
#freqs = rowSums(as.matrix(dtm))#
#
#plot(sort(freqs, dec=T), type="l", log="xy", ylab="frequency (log-scaled)", xlab="terms (log-scaled)")#
#
#greater10 = length(which(freqs > ncol(dtm)/10))#
#greater25 = length(which(freqs > ncol(dtm)/4))#
#greater50 = length(which(freqs > ncol(dtm)/2))#
#
#justonce = length(which(freqs>1))#
#justtwice = length(which(freqs>2))#
#just5 = length(which(freqs>5))#
#
#rect(greater25,ncol(dtm)/4, justtwice, 2, lty="dotted", col=rgb(0.3,0.3,0.3, alpha=0.1))#
#
#text(greater10+20, 10+ncol(dtm)/10, paste(greater10, "> 10%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/10, lty="dashed", col="darkgreen")#
#
#text(greater25+15, 20+ncol(dtm)/4, paste(greater25, "> 25%", sep=" "), col="darkgreen", cex=0.7, font=2)#
#abline(h=ncol(dtm)/4, lty="dashed", col="darkgreen")#
#
#text(greater50+2, 20+ncol(dtm)/2, paste(greater50, "> 50%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/2, lty="dashed", col="darkgreen")#
#
#abline(v=justonce, lty="dotted", col="darkred")#
#text(justonce-400, 1, paste(justonce,">1",sep=" "), col="darkred", cex=0.7)#
#
#abline(v=justtwice, lty="dotted", col="darkred")#
#text(justtwice-300, 2, paste(justtwice,">2",sep=" "), col="darkred", cex=0.7, font=2)#
#
#abline(v=just5, lty="dotted", col="darkred")#
#text(just5-50, 4, paste(just5,">5",sep=" "), col="darkred", cex=0.7)#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# filtering by threshold#
#
lower = which(freqs>1)#
dtm = dtm[lower,]#
#
freqs = rowSums(as.matrix(dtm))#
upper = which(freqs < ncol(dtm)/4)#
dtm = dtm[upper,]#
#
empty = as.integer( which(colSums(as.matrix(dtm))==0) )#
dtm = dtm[,-(empty)]#
#
# t2t size:#
nrow(dtm)^2 * 8 / 1024 / 1024#
# 15.97449 MB#
#
dtm = as.matrix(dtm)#
#
proc.time() - a
a = proc.time()#
#
essays.content = read.csv2(file="~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.content.csv", stringsAsFactors=FALSE)#
#
tm = Corpus(#
        VectorSource(essays.content[,2]),#
        readerControl=list(#
            reader=readPlain, language="de",#
            load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE#
        )#
    )#
#
tm = tm_map(tm, function(e) return(gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", e)))#
tm = tm_map(tm, tolower)#
#
# save full dictionary for stem completion#
dict = Terms(DocumentTermMatrix(#
	tm,#
	control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)#
))#
#
length(dict)#
#
# stemming#
tm = tm_map(tm, stemDocument, language="ger")#
dtm = TermDocumentMatrix(tm, control = list(#
    removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
    minWordLength = 3, bounds = list(global=c(1,Inf))#
))#
#
dim(dtm)#
#
# stem completion#
sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
#
rownames(dtm) = sc#
if (any(duplicated(rownames(dtm)))) {#
    dupes = which(duplicated(rownames(dtm)))#
    for (i in dupes) {#
        #cat(paste("removing dupe for ", sc[i], "\n", sep=""))#
		hits = which(sc == sc[i])#
        target = hits[ which(! hits %in% which(duplicated(sc))) ]#
        replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
        rownames(replvec) = sc[target]#
        dtm[ target,1:length(replvec) ] = replvec#
    }#
    dtm = dtm[!duplicated(rownames(dtm)),]#
}#
class(dtm) = c("TermDocumentMatrix", class(dtm))#
#
dim(dtm)#
#
if (any(rownames(dtm) == "")) {#
    cat("removing empty ones")#
    dtm = dtm[-(which(rownames(dtm) == "")), ]#
}#
#
dim(dtm)#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# check for outliers: plot freq dist with chosen upper/lower threshold window#
# commented for performance benchmark: just uncomment!#
#
freqs = rowSums(as.matrix(dtm))#
#
#plot(sort(freqs, dec=T), type="l", log="xy", ylab="frequency (log-scaled)", xlab="terms (log-scaled)")#
#
#greater10 = length(which(freqs > ncol(dtm)/10))#
#greater25 = length(which(freqs > ncol(dtm)/4))#
#greater50 = length(which(freqs > ncol(dtm)/2))#
#
#justonce = length(which(freqs>1))#
#justtwice = length(which(freqs>2))#
#just5 = length(which(freqs>5))#
#
#rect(greater25,ncol(dtm)/4, justtwice, 2, lty="dotted", col=rgb(0.3,0.3,0.3, alpha=0.1))#
#
#text(greater10+20, 10+ncol(dtm)/10, paste(greater10, "> 10%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/10, lty="dashed", col="darkgreen")#
#
#text(greater25+15, 20+ncol(dtm)/4, paste(greater25, "> 25%", sep=" "), col="darkgreen", cex=0.7, font=2)#
#abline(h=ncol(dtm)/4, lty="dashed", col="darkgreen")#
#
#text(greater50+2, 20+ncol(dtm)/2, paste(greater50, "> 50%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/2, lty="dashed", col="darkgreen")#
#
#abline(v=justonce, lty="dotted", col="darkred")#
#text(justonce-400, 1, paste(justonce,">1",sep=" "), col="darkred", cex=0.7)#
#
#abline(v=justtwice, lty="dotted", col="darkred")#
#text(justtwice-300, 2, paste(justtwice,">2",sep=" "), col="darkred", cex=0.7, font=2)#
#
#abline(v=just5, lty="dotted", col="darkred")#
#text(just5-50, 4, paste(just5,">5",sep=" "), col="darkred", cex=0.7)#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# filtering by threshold#
#
lower = which(freqs>1)#
dtm = dtm[lower,]#
#
freqs = rowSums(as.matrix(dtm))#
upper = which(freqs < ncol(dtm)/4)#
dtm = dtm[upper,]#
#
empty = as.integer( which(colSums(as.matrix(dtm))==0) )#
dtm = dtm[,-(empty)]#
#
# t2t size:#
nrow(dtm)^2 * 8 / 1024 / 1024#
# 15.97449 MB#
#
dtm = as.matrix(dtm)#
#
proc.time() - a
library(mpia)
a = proc.time()#
#
essays.content = read.csv2(file="~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.content.csv", stringsAsFactors=FALSE)#
#
tm = Corpus(#
        VectorSource(essays.content[,2]),#
        readerControl=list(#
            reader=readPlain, language="de",#
            load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE#
        )#
    )#
#
tm = tm_map(tm, function(e) return(gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", e)))#
tm = tm_map(tm, tolower)#
#
# save full dictionary for stem completion#
dict = Terms(DocumentTermMatrix(#
	tm,#
	control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)#
))#
#
length(dict)#
#
# stemming#
tm = tm_map(tm, stemDocument, language="ger")#
dtm = TermDocumentMatrix(tm, control = list(#
    removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
    minWordLength = 3, bounds = list(global=c(1,Inf))#
))#
#
dim(dtm)#
#
# stem completion#
sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
#
rownames(dtm) = sc#
if (any(duplicated(rownames(dtm)))) {#
    dupes = which(duplicated(rownames(dtm)))#
    for (i in dupes) {#
        #cat(paste("removing dupe for ", sc[i], "\n", sep=""))#
		hits = which(sc == sc[i])#
        target = hits[ which(! hits %in% which(duplicated(sc))) ]#
        replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
        rownames(replvec) = sc[target]#
        dtm[ target,1:length(replvec) ] = replvec#
    }#
    dtm = dtm[!duplicated(rownames(dtm)),]#
}#
class(dtm) = c("TermDocumentMatrix", class(dtm))#
#
dim(dtm)#
#
if (any(rownames(dtm) == "")) {#
    cat("removing empty ones")#
    dtm = dtm[-(which(rownames(dtm) == "")), ]#
}#
#
dim(dtm)#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# check for outliers: plot freq dist with chosen upper/lower threshold window#
# commented for performance benchmark: just uncomment!#
#
freqs = rowSums(as.matrix(dtm))#
#
#plot(sort(freqs, dec=T), type="l", log="xy", ylab="frequency (log-scaled)", xlab="terms (log-scaled)")#
#
#greater10 = length(which(freqs > ncol(dtm)/10))#
#greater25 = length(which(freqs > ncol(dtm)/4))#
#greater50 = length(which(freqs > ncol(dtm)/2))#
#
#justonce = length(which(freqs>1))#
#justtwice = length(which(freqs>2))#
#just5 = length(which(freqs>5))#
#
#rect(greater25,ncol(dtm)/4, justtwice, 2, lty="dotted", col=rgb(0.3,0.3,0.3, alpha=0.1))#
#
#text(greater10+20, 10+ncol(dtm)/10, paste(greater10, "> 10%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/10, lty="dashed", col="darkgreen")#
#
#text(greater25+15, 20+ncol(dtm)/4, paste(greater25, "> 25%", sep=" "), col="darkgreen", cex=0.7, font=2)#
#abline(h=ncol(dtm)/4, lty="dashed", col="darkgreen")#
#
#text(greater50+2, 20+ncol(dtm)/2, paste(greater50, "> 50%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/2, lty="dashed", col="darkgreen")#
#
#abline(v=justonce, lty="dotted", col="darkred")#
#text(justonce-400, 1, paste(justonce,">1",sep=" "), col="darkred", cex=0.7)#
#
#abline(v=justtwice, lty="dotted", col="darkred")#
#text(justtwice-300, 2, paste(justtwice,">2",sep=" "), col="darkred", cex=0.7, font=2)#
#
#abline(v=just5, lty="dotted", col="darkred")#
#text(just5-50, 4, paste(just5,">5",sep=" "), col="darkred", cex=0.7)#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# filtering by threshold#
#
lower = which(freqs>1)#
dtm = dtm[lower,]#
#
freqs = rowSums(as.matrix(dtm))#
upper = which(freqs < ncol(dtm)/4)#
dtm = dtm[upper,]#
#
empty = as.integer( which(colSums(as.matrix(dtm))==0) )#
dtm = dtm[,-(empty)]#
#
# t2t size:#
nrow(dtm)^2 * 8 / 1024 / 1024#
# 15.97449 MB#
#
dtm = as.matrix(dtm)#
#
proc.time() - a
dim(dtm)
# superfast#
tr = sum(dtm*dtm)#
tr#
# 20887#
#
tr * 0.8#
# 16709.6#
#
#save(space, file="~/Documents/mpia/space-essaysonly-raw.RData")#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# find ideal truncation (recalc tr or use from above)#
#
# check if svd was calculated with enough dimensions (here: true, since dimcalc_raw() was used)#
if ( ! tr*0.8<sum(space$sk^2) ) stop("svd has too few factors!")#
#
# find cutoff#
threshold = tr * 0.8#
r = 0#
for (i in 1:length(space$sk)) {#
    r = r + (space$sk[i]^2)#
    if (r >= threshold) {#
        cutoff = i-1#
        break()#
    }#
}#
#
cutoff
a = proc.time()#
space = lsa(dtm, dims=dimcalc_raw())#
proc.time()-a#
# superfast#
tr = sum(dtm*dtm)#
tr#
# 20887#
#
tr * 0.8#
# 16709.6#
#
#save(space, file="~/Documents/mpia/space-essaysonly-raw.RData")#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# find ideal truncation (recalc tr or use from above)#
#
# check if svd was calculated with enough dimensions (here: true, since dimcalc_raw() was used)#
if ( ! tr*0.8<sum(space$sk^2) ) stop("svd has too few factors!")#
#
# find cutoff#
threshold = tr * 0.8#
r = 0#
for (i in 1:length(space$sk)) {#
    r = r + (space$sk[i]^2)#
    if (r >= threshold) {#
        cutoff = i-1#
        break()#
    }#
}#
#
cutoff
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
dtm = Matrix(dtm)
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
class(dtm) = "matrix"
dtm = Matrix(dtm)
dtm
dim(dtm
)
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
class(dtm) = "dgCMatrix"
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a
dtm = as.matrix(dtm)
dtm
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
dtm = Matrix(dtm)
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
source("~/Documents/werkstatt/lsa-package/lsa/pkg/lsa/R/svdlibc.R")
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=cutoff)#
proc.time()-a
1 - 1.353 / 3.433
q()
library(mpia)
im = matrix(0, nrow=9, ncol=12)#
#
rownames(im) = c("Paul", "Joanna", "Maximilian", "Peter", "Christina", "Simon", "Ida", "Thomas", "Alba")#
#
colnames(im) = c("OU-CS", "UR-Informatik", "MOOC-PED", "MOOC-TEL", "MOOC-Math", "OU-PED", "MOOC-ocTEL",#
"MOOC-LAK", "OU-Statistics", "Facebook-Statistics", "Facebook-TEL", "Linkedin-CS")#
#
im[1, ] = c(1,1,0,0,0,0,0,0,0,0,0,1) # paul#
im[2, ] = c(0,0,1,0,0,1,0,0,0,0,1,0) # joanna#
im[3, ] = c(0,0,0,0,1,0,0,0,0,1,0,0) # max#
im[4, ] = c(0,0,0,1,0,1,1,1,0,0,0,0) # peter#
im[5, ] = c(0,0,1,1,0,1,1,1,0,0,0,0) # christina#
im[6, ] = c(0,1,0,0,0,0,0,0,0,0,0,1) # simon#
im[7, ] = c(0,0,0,0,0,0,0,0,1,1,0,0) # ida#
im[8, ] = c(0,0,0,0,0,0,0,0,1,1,0,0) # thomas#
im[9, ] = c(0,0,0,1,0,0,1,1,0,0,0,0) # alba#
#
# 2) plot sociograms#
#
par(mar=c(3,2,3,2))#
par(mfrow=c(2,2))#
par(cex.lab=0.6)#
#
plot(network(im%*%t(im)), displaylabels=T, vertex.cex=2, main="Affiliations") # three communities#
#
colors = c(rep("red",nrow(im)),rep("white",ncol(im)))#
plot(network(im), displaylabels=T, vertex.col=colors, vertex.cex=2, main="Incidences") # the communities are: TEL, CS, Math#
#
# 3) manipulate data: merge courses#
#
TEL = c(	"OU-CS", "UR-Informatik", "Linkedin-CS", "MOOC-PED","OU-PED", "MOOC-TEL","MOOC-ocTEL","MOOC-LAK", "Facebook-TEL")#
STATS = c("MOOC-Math", "OU-Statistics", "Facebook-Statistics")#
im_new = cbind(#
	rowSums( im[, TEL] ),#
	rowSums( im[, STATS] )#
)#
colnames(im_new) = c("ALL-TEL", "ALL-STATS")#
#
# 4) plot sociograms (again)#
#
plot(network(im_new %*% t(im_new), directed=FALSE), displaylabels=TRUE, vertex.cex=2, main="Affiliations (manipulated)")#
#
colors = c(rep("red",nrow(im)),rep("white",ncol(im)))#
plot(network(im_new>0, directed=FALSE), displaylabels=TRUE, vertex.col=colors, vertex.cex=2, main="Incidences (manipulated)")#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# demo: latent semantic space#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# create a demo data set#
#
docs = matrix(nrow=0, ncol=2)#
colnames(docs) = c("id", "title")#
#
docs = rbind( docs, c("c1", "a web interface for social media applications")) # web social interface#
docs = rbind( docs, c("c2", "Review of access time restrictions on web system usage")) # web access review system time user#
docs = rbind( docs, c("c3", "Content management system usage of the HTML 5 interface")) # interface system html management#
docs = rbind( docs, c("c4", "Error spotting in HTML: social system versus software system")) # social 2x system html#
docs = rbind( docs, c("c5", "Barriers to access and time spent in social mobile apps")) # access time social#
#
docs = rbind( docs, c("m1", "The generation of random unordered trees")) # trees#
docs = rbind( docs, c("m2", "A survey of divisive clustering along the intersection of partial trees")) # trees clustering intersection#
docs = rbind( docs, c("m3", "Width and height of trees in using agglomerative clustering with Agnes")) # trees clustering agglomerative#
docs = rbind( docs, c("m4", "Agglomerative clustering algorithms: a review")) # clustering agglomerative review#
#
docs = rbind( docs, c("p1", "The intersection of learning and organisational knowledge sharing"))#
docs = rbind( docs, c("p2", "A transactional perspective on teaching and learning"))#
docs = rbind( docs, c("p3", "Innovations in online learning: moving beyond no significant difference"))#
docs = rbind( docs, c("p4", "Tacit knowledge management in organisational learning"))#
docs = rbind( docs, c("p5", "Knowledge building: theory, pedagogy, and technology"))#
#
# create doc term matrix#
#
docs2 = docs[,2]#
docs2 = tolower(docs2)#
docs2 = gsub("[^[:alnum:]]", " ", docs2)#
docs2 = gsub("[[:space:]]+", " ", docs2)#
docs2 = lapply(docs2, function (e) { unlist(strsplit(e, " ")) })#
data(stopwords_en)#
docs2 = lapply(docs2, function (e) { e[! (e %in% stopwords_en) ] })#
tabs = lapply(docs2, function(e){sort(table(e), dec=T)})#
tabs2 = lapply(tabs, function(e) { data.frame(docs = "", terms = names(e), Freq = e, row.names = NULL) })#
for (i in 1:nrow(docs)) { tabs2[[i]][,1]= docs[i,1] }
dtm = t(xtabs(Freq ~ ., data = do.call("rbind", tabs2)))#
dtm = dtm[-which(rowSums(dtm)<=1),] # at least in more than a single document#
dtm
space = lsa(dtm, dims=dimcalc_raw())
space$sk
dimcalc_var(space$sk)
dimcalc_var()(space$sk)
dmgr = DomainManager()#
id = dmgr$add(space, title="memospace")#
d = dmgr$get("memospace")#
#
# create data (binding training description -> person attending)#
#
dmsg = c( 1,2,10,3,6,11,4,7,8,9,12,5 )#
cbind( docs[dmsg,1], as.matrix(colnames(im)))#
#
thedocs = cbind( docs[dmsg,1], as.matrix(colnames(im)), docs[dmsg,2])#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
for (p in rownames(im)) {#
   assign(tolower(p), ppl$add(name=p))#
   for (pf in which(im[p,]>0)) {#
      #get(tolower(p))$write(docs[dmsg,][pf,2], label=docs[dmsg,][pf,1], purpose=colnames(im)[pf])#
      get(tolower(p))$write(thedocs[pf,3], label=thedocs[pf,1], purpose=colnames(im)[pf])#
   }#
}#
#
thedocs2 = cbind( as.matrix(colnames(im)),docs[dmsg,2] )#
rownames(thedocs2) =  docs[dmsg,1]#
colnames(thedocs2) = c("Training", "Description")#
thedocs2 = thedocs2[sort(rownames(thedocs2), index.return=TRUE)$ix, ]#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# visual analysis: first demo#
#
par(mfrow=c(2,2))#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="The MPIA space")#
toponymy(d, method="all", add=TRUE, col="black")#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="Peter's path (of performance records)")#
toponymy(d, method="all", add=TRUE, col="black")#
plot(path(peter), col="white")
peter[1] == peter[3]
ls()
paul
dmgr = DomainManager()#
id = dmgr$add(space, title="memospace")#
d = dmgr$get("memospace")#
#
# create data (binding training description -> person attending)#
#
dmsg = c( 1,2,10,3,6,11,4,7,8,9,12,5 )#
cbind( docs[dmsg,1], as.matrix(colnames(im)))#
#
thedocs = cbind( docs[dmsg,1], as.matrix(colnames(im)), docs[dmsg,2])#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
for (p in rownames(im)) {#
   assign(tolower(p), ppl$add(name=p))#
   for (pf in which(im[p,]>0)) {#
      #get(tolower(p))$write(docs[dmsg,][pf,2], label=docs[dmsg,][pf,1], purpose=colnames(im)[pf])#
      get(tolower(p))$write(thedocs[pf,3], label=thedocs[pf,1], purpose=colnames(im)[pf])#
   }#
}#
#
thedocs2 = cbind( as.matrix(colnames(im)),docs[dmsg,2] )#
rownames(thedocs2) =  docs[dmsg,1]#
colnames(thedocs2) = c("Training", "Description")#
thedocs2 = thedocs2[sort(rownames(thedocs2), index.return=TRUE)$ix, ]
space = lsa(dtm, dims=3)
dmgr = DomainManager()#
id = dmgr$add(space, title="memospace")#
d = dmgr$get("memospace")#
#
# create data (binding training description -> person attending)#
#
dmsg = c( 1,2,10,3,6,11,4,7,8,9,12,5 )#
cbind( docs[dmsg,1], as.matrix(colnames(im)))#
#
thedocs = cbind( docs[dmsg,1], as.matrix(colnames(im)), docs[dmsg,2])#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
for (p in rownames(im)) {#
   assign(tolower(p), ppl$add(name=p))#
   for (pf in which(im[p,]>0)) {#
      #get(tolower(p))$write(docs[dmsg,][pf,2], label=docs[dmsg,][pf,1], purpose=colnames(im)[pf])#
      get(tolower(p))$write(thedocs[pf,3], label=thedocs[pf,1], purpose=colnames(im)[pf])#
   }#
}#
#
thedocs2 = cbind( as.matrix(colnames(im)),docs[dmsg,2] )#
rownames(thedocs2) =  docs[dmsg,1]#
colnames(thedocs2) = c("Training", "Description")#
thedocs2 = thedocs2[sort(rownames(thedocs2), index.return=TRUE)$ix, ]#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# visual analysis: first demo#
#
par(mfrow=c(2,2))#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="The MPIA space")#
toponymy(d, method="all", add=TRUE, col="black")#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="Peter's path (of performance records)")#
toponymy(d, method="all", add=TRUE, col="black")#
plot(path(peter), col="white")#
#
# two performance records are identical!#
peter[1] == peter[3]#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="Peter's competences and position")#
plot(competences(peter), col="red", component.labels=FALSE, connect=FALSE, alpha=1)#
plot(position(peter), col="orange")#
#
plot(d, method="persp", rotated=TRUE)#
par(mar=c(1,1,1,1))#
title(main="Peter's learning path (in shades of gray)")#
pf = path(peter)#
cs = gray(seq(1,0.5,length.out=length(pf) ))#
for (p in 1:length(pf)) {#
	plot(pf[[p]], col=cs[p])#
}
dim(dtm)
dtm = t(xtabs(Freq ~ ., data = do.call("rbind", tabs2)))
dim(dtm)
a = proc.time()#
#
docs = matrix(nrow=0, ncol=2)#
colnames(docs) = c("id", "title")#
#
docs = rbind( docs, c("c1", "a web interface for social media applications")) # web social interface#
docs = rbind( docs, c("c2", "Review of access time restrictions on web system usage")) # web access review system time user#
docs = rbind( docs, c("c3", "Content management system usage of the HTML 5 interface")) # interface system html management#
docs = rbind( docs, c("c4", "Error spotting in HTML: social system versus software system")) # social 2x system html#
docs = rbind( docs, c("c5", "Barriers to access and time spent in social mobile apps")) # access time social#
#
docs = rbind( docs, c("m1", "The generation of random unordered trees")) # trees#
docs = rbind( docs, c("m2", "A survey of divisive clustering along the intersection of partial trees")) # trees clustering intersection#
docs = rbind( docs, c("m3", "Width and height of trees in using agglomerative clustering with Agnes")) # trees clustering agglomerative#
docs = rbind( docs, c("m4", "Agglomerative clustering algorithms: a review")) # clustering agglomerative review#
#
docs = rbind( docs, c("p1", "The intersection of learning and organisational knowledge sharing"))#
docs = rbind( docs, c("p2", "A transactional perspective on teaching and learning"))#
docs = rbind( docs, c("p3", "Innovations in online learning: moving beyond no significant difference"))#
docs = rbind( docs, c("p4", "Tacit knowledge management in organisational learning"))#
docs = rbind( docs, c("p5", "Knowledge building: theory, pedagogy, and technology"))#
#
# create doc term matrix#
#
docs2 = docs[,2]#
docs2 = tolower(docs2)#
docs2 = gsub("[^[:alnum:]]", " ", docs2)#
docs2 = gsub("[[:space:]]+", " ", docs2)#
docs2 = lapply(docs2, function (e) { unlist(strsplit(e, " ")) })#
data(stopwords_en)#
docs2 = lapply(docs2, function (e) { e[! (e %in% stopwords_en) ] })#
tabs = lapply(docs2, function(e){sort(table(e), dec=T)})#
tabs2 = lapply(tabs, function(e) { data.frame(docs = "", terms = names(e), Freq = e, row.names = NULL) })#
for (i in 1:nrow(docs)) { tabs2[[i]][,1]= docs[i,1] }#
#
dtm = t(xtabs(Freq ~ ., data = do.call("rbind", tabs2)))#
dtm = dtm[-which(rowSums(dtm)<=1),] # at least in more than a single document#
#
proc.time() - a
0.206 + 0.450 + 0.282 + 0.456 / 4
(0.206 + 0.450 + 0.282 + 0.456) / 4
round(0.5)
dtm = Matrix(dtm)
source("~/Documents/werkstatt/lsa-package/lsa/pkg/lsa/R/svdlibc.R")#
#
a = proc.time()#
space = lsa_sparse(dtm, ndim=min(ncol(dtm), nrow(dtm)))#
proc.time()-a#
a = proc.time()#
space = lsa_sparse(dtm, ndim=3)#
proc.time()-a
1- 0.505/0.507
q()
library(mpia)
load("/Volumes/crunch.kmi.open.ac.uk/augur_bak/v2/wp2/files/spaces/117/space.RData")
dim(space$tk)
dim(space$dk)
load("/Volumes/crunch.kmi.open.ac.uk/augur_bak/v2/wp2/files/spaces/117/control_pre.RData")
ls()
control
q()
library(tm)
library(lsa)
library(mpia)
dmgr = DomainManager()#
dmgr$tempdir = "~/Documents/werkstatt/mpia-package/cache/"#
d = dmgr$get(name="essays")
summary(d)
plot(d, method="topographic")
scorefiles = dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.scores/", full.names=TRUE)#
humanscores=NULL#
for (i in 1:length(scorefiles)) {#
	humanscores = rbind(humanscores, read.table(scorefiles[i], col.names=c("file","score"),row.names="file"))#
}#
#
set.seed(22031977)#
firstnames = c(#
	readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[1], warn=F),#
	readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[2], warn=F)#
)#
student.names = firstnames[sample(length(firstnames),nrow(essays.content))]
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)
setwd("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/")#
#
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)
scorefiles = dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays.scores/", full.names=TRUE)#
humanscores=NULL#
for (i in 1:length(scorefiles)) {#
	humanscores = rbind(humanscores, read.table(scorefiles[i], col.names=c("file","score"),row.names="file"))#
}#
#
set.seed(22031977)#
firstnames = c(#
	readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[1], warn=F),#
	readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[2], warn=F)#
)#
student.names = firstnames[sample(length(firstnames),nrow(essays.content))]
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
d$traces = matrix(ncol=0, nrow=0)
cs = c("firebrick", "chartreuse4", "darkorchid4", "black", "deeppink3", "orange4", "cadetblue4", "goldenrod2", "deepskyblue2", "antiquewhite3")#
#
oldds = ""#
essays = NULL#
essays.scores = NULL#
#
for (i in 1:nrow(essays.content)) {#
    ds = strsplit(substr(essays.content[i,1], 5, nchar(essays.content[i,1])), "[_\\.]")[[1]][1]#
    if (ds != oldds) { n = 1;oldds=ds} else n = n+1#
    essays.scores[i] = humanscores[essays.content[i,1],1]#
    student.names[i] = paste( student.names[i], " (", ds,")", sep="" )#
    p = ppl$add( name=student.names[i] )#
    essays[i] = gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", essays.content[i,2])#
    p$perform( essays[i], activity="exam", purpose="exam", score=essays.scores[i])#
    #plot(p, col=cs[as.integer(ds)], label=FALSE, component.labels=FALSE, component.arrows=F, dot.cex=1)#
    print(i)#
}
plot(d, method="topographic")#
collection = as.integer( gsub("_", "", substr(essays.content[,1], 5, 6)) )#
cs = c("firebrick", "chartreuse4", "darkorchid4", "black", "deeppink3", "orange4", "cadetblue4", "goldenrod2", "deepskyblue2", "black")#
for (p in 1:length(ppl$people)) plot(ppl$people[[p]], col=cs[collection][p], label=FALSE, component.labels=FALSE, component.arrows=F, dot.cex=1)
warnings()
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
d$traces = matrix(ncol=0, nrow=0)#
gc()#
#
plot(d, method="topographic")#
#
set.seed(22031977)#
firstnames = c(#
readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[1], warn=F),#
readLines(dir("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/names/", full.names=TRUE)[2], warn=F)#
)#
student.names = firstnames[sample(length(firstnames),nrow(essays.content))]#
#
oldds = ""#
essays = NULL#
essays.scores = NULL#
for (i in 1:102) {#
    if (i!=41) {#
        ds = strsplit(substr(essays.content[i,1], 5, nchar(essays.content[i,1])), "[_\\.]")[[1]][1]#
        if (ds != oldds) { n = 1;oldds=ds} else n = n+1#
        essays.scores[i] = humanscores[essays.content[i,1],1]#
        student.names[i] = paste( student.names[i], " (", ds,")", sep="" )#
        p = ppl$add( name=student.names[i] )#
        essays[i] = gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", essays.content[i,2])#
        p$perform( essays[i], activity="exam", purpose="exam", score=essays.scores[i])#
        plot(p, col= cs[as.integer(ds)], label=FALSE, component.labels=FALSE, component.arrows=F, dot.cex=1) # gray(1-(essays.scores[i]/5)/8)#
        print(i)#
    } # empty ones removed#
}
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)#
# golds#
#
seeddir = "essays.base/seed/"#
#
fcorpus = c( dir(seeddir, recursive=TRUE, full.names=TRUE) )#
length(fcorpus)#
#
fnessays = basename( c( dir(seeddir, recursive=TRUE)) )#
length(fnessays)#
#
gold = basename( dir(seeddir, recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
thegolds = cbind(fnessays, content)#
#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
goldpers = ppl$add(name="goldstandards")#
#
for (i in 1:nrow(thegolds)) {#
    goldpers$perform( thegolds[i,2], activity="exam", purpose="exam")#
}#
#
mv = goldpers$getMeaningVectors()#
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))#
colnames(goldsdtm) = thegolds[,1]#
#
# mix with essays#
#
fulldtm = cbind(as.textmatrix(d$space), goldsdtm)#
e2e = lsa::cosine(fulldtm)#
#
rownames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
colnames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
#
e2e[1:10,1:10]#
#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
#
}
dim(mv)
lost
setwd("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/")#
#
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)#
# golds#
#
seeddir = "essays.base/seed/"#
#
fcorpus = c( dir(seeddir, recursive=TRUE, full.names=TRUE) )#
length(fcorpus)#
#
fnessays = basename( c( dir(seeddir, recursive=TRUE)) )#
length(fnessays)#
#
gold = basename( dir(seeddir, recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
thegolds = cbind(fnessays, content)#
#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
goldpers = ppl$add(name="goldstandards")#
#
for (i in 1:nrow(thegolds)) {#
    goldpers$perform( thegolds[i,2], activity="exam", purpose="exam")#
}#
#
mv = goldpers$getMeaningVectors()#
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))#
colnames(goldsdtm) = thegolds[,1]#
#
# mix with essays#
#
fulldtm = cbind(as.textmatrix(d$space), goldsdtm)#
e2e = lsa::cosine(fulldtm)#
#
rownames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
colnames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
#
e2e[1:10,1:10]#
#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
#
}
mv
dim(d$space$tk)
d$identityThreshold
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), mv)
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))
as.textmatrix
goldsdtm = crossprod(crossprod(t(space$tk), diag(space$sk)), t(mv))
goldsdtm = crossprod(crossprod(t(space$tk), diag(space$sk)), (mv))
goldsdtm = crossprod(crossprod(t(space$tk), diag(space$sk)), t(mv))
dim(space$tk)
dmgr = DomainManager()#
dmgr$tempdir = "~/Documents/werkstatt/mpia-package/cache/"#
d = dmgr$get(name="essays")#
space = d$space
dim(space)
d
d$space
space = d$space
class(space) = "LSAspace"
space
setwd("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/")#
#
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)#
# golds#
#
seeddir = "essays.base/seed/"#
#
fcorpus = c( dir(seeddir, recursive=TRUE, full.names=TRUE) )#
length(fcorpus)#
#
fnessays = basename( c( dir(seeddir, recursive=TRUE)) )#
length(fnessays)#
#
gold = basename( dir(seeddir, recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
thegolds = cbind(fnessays, content)#
#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
goldpers = ppl$add(name="goldstandards")#
#
for (i in 1:nrow(thegolds)) {#
    goldpers$perform( thegolds[i,2], activity="exam", purpose="exam")#
}#
#
mv = goldpers$getMeaningVectors()#
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))#
colnames(goldsdtm) = thegolds[,1]#
#
# mix with essays#
#
fulldtm = cbind(as.textmatrix(d$space), goldsdtm)#
e2e = lsa::cosine(fulldtm)#
#
rownames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
colnames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
#
e2e[1:10,1:10]#
#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
#
}
corpus = "~/Documents/mpia/essays"#
#
fcorpus = dir(corpus, recursive=TRUE, full.names=TRUE)#
fnessays = basename( dir("~/Documents/mpia/essays", recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    #output = c(output, paste(f, ". trying iso\n", sep=""))#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        #output = c(output, paste(f, ". trying utf8\n", sep=""))#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
#
essays.content = cbind(fnessays, content)
f
corpus = "~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/essays"#
#
fcorpus = dir(corpus, recursive=TRUE, full.names=TRUE)#
fnessays = basename( dir(corpus, recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    #output = c(output, paste(f, ". trying iso\n", sep=""))#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        #output = c(output, paste(f, ". trying utf8\n", sep=""))#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
#
essays.content = cbind(fnessays, content)
setwd("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/")#
#
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)#
#
tm = Corpus(#
        VectorSource(essays.content[,2]),#
        readerControl=list(#
            reader=readPlain, language="de",#
            load=TRUE, removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE#
        )#
    )#
#
tm = tm_map(tm, function(e) return(gsub("[^a-zA-Z0-9äöüÄÖÜß]", " ", e)))#
tm = tm_map(tm, tolower)#
#
# save full dictionary for stem completion#
dict = Terms(DocumentTermMatrix(#
	tm,#
	control=list(removePunctuation=TRUE, stopwords=TRUE, minWordLength=3, removeNumbers=TRUE)#
))#
#
length(dict)#
#
# stemming#
tm = tm_map(tm, stemDocument, language="ger")#
dtm = TermDocumentMatrix(tm, control = list(#
    removePunctuation = TRUE, removeNumbers = TRUE, stopwords = TRUE,#
    minWordLength = 3, bounds = list(global=c(1,Inf))#
))#
#
dim(dtm)#
#
# stem completion#
sc = as.character( stemCompletion(rownames(dtm), dictionary=dict, type="shortest") )#
sc[which(is.na(sc))] = rownames(dtm)[which(is.na(sc))]#
#
rownames(dtm) = sc#
if (any(duplicated(rownames(dtm)))) {#
    dupes = which(duplicated(rownames(dtm)))#
    for (i in dupes) {#
        #cat(paste("removing dupe for ", sc[i], "\n", sep=""))#
		hits = which(sc == sc[i])#
        target = hits[ which(! hits %in% which(duplicated(sc))) ]#
        replvec = t(as.matrix( colSums(as.matrix(dtm[ hits, ])) ))#
        rownames(replvec) = sc[target]#
        dtm[ target,1:length(replvec) ] = replvec#
    }#
    dtm = dtm[!duplicated(rownames(dtm)),]#
}#
class(dtm) = c("TermDocumentMatrix", class(dtm))#
#
dim(dtm)#
#
if (any(rownames(dtm) == "")) {#
    cat("removing empty ones")#
    dtm = dtm[-(which(rownames(dtm) == "")), ]#
}#
#
dim(dtm)#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# check for outliers: plot freq dist with chosen upper/lower threshold window#
#
freqs = rowSums(as.matrix(dtm))#
#
# commented for performance benchmark: just uncomment!#
#
#plot(sort(freqs, dec=T), type="l", log="xy", ylab="frequency (log-scaled)", xlab="terms (log-scaled)")#
#
#greater10 = length(which(freqs > ncol(dtm)/10))#
#greater25 = length(which(freqs > ncol(dtm)/4))#
#greater50 = length(which(freqs > ncol(dtm)/2))#
#
#justonce = length(which(freqs>1))#
#justtwice = length(which(freqs>2))#
#just5 = length(which(freqs>5))#
#
#rect(greater25,ncol(dtm)/4, justtwice, 2, lty="dotted", col=rgb(0.3,0.3,0.3, alpha=0.1))#
#
#text(greater10+20, 10+ncol(dtm)/10, paste(greater10, "> 10%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/10, lty="dashed", col="darkgreen")#
#
#text(greater25+15, 20+ncol(dtm)/4, paste(greater25, "> 25%", sep=" "), col="darkgreen", cex=0.7, font=2)#
#abline(h=ncol(dtm)/4, lty="dashed", col="darkgreen")#
#
#text(greater50+2, 20+ncol(dtm)/2, paste(greater50, "> 50%", sep=" "), col="darkgreen", cex=0.7)#
#abline(h=ncol(dtm)/2, lty="dashed", col="darkgreen")#
#
#abline(v=justonce, lty="dotted", col="darkred")#
#text(justonce-400, 1, paste(justonce,">1",sep=" "), col="darkred", cex=0.7)#
#
#abline(v=justtwice, lty="dotted", col="darkred")#
#text(justtwice-300, 2, paste(justtwice,">2",sep=" "), col="darkred", cex=0.7, font=2)#
#
#abline(v=just5, lty="dotted", col="darkred")#
#text(just5-50, 4, paste(just5,">5",sep=" "), col="darkred", cex=0.7)#
#
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# filtering by threshold#
#
lower = which(freqs>1)#
dtm = dtm[lower,]#
#
freqs = rowSums(as.matrix(dtm))#
upper = which(freqs < ncol(dtm)/4)#
dtm = dtm[upper,]#
#
empty = as.integer( which(colSums(as.matrix(dtm))==0) )#
dtm = dtm[,-(empty)]#
#
# t2t size:#
nrow(dtm)^2 * 8 / 1024 / 1024#
# 15.97449 MB#
#
dtm = as.matrix(dtm)#
#
proc.time() - a#
#
class(dtm) = "textmatrix"
space = lsa(dtm, dims=dimcalc_raw())
tr = sum(dtm*dtm)#
tr
tr * 0.8
if ( ! tr*0.8<sum(space$sk^2) ) stop("svd has too few factors!")#
#
# find cutoff#
threshold = tr * 0.8#
r = 0#
for (i in 1:length(space$sk)) {#
    r = r + (space$sk[i]^2)#
    if (r >= threshold) {#
        cutoff = i-1#
        break()#
    }#
}#
#
cutoff
# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -#
# truncate#
#
space$tk = space$tk[, 1:cutoff]#
space$dk = space$dk[, 1:cutoff]#
space$sk = space$sk[ 1:cutoff ]
empty
dmgr = DomainManager()#
dmgr$tempdir = "~/Documents/werkstatt/mpia-package/cache/"#
d = dmgr$get(name="essays")#
space = d$space
dim(space$dk)
dim(space$dk)
setwd("~/Documents/werkstatt/mpia-package/mpia-package/pkg/mpia/work/")#
#
essays.content = read.csv2(file="essays.content.csv", stringsAsFactors=FALSE)#
# golds#
#
seeddir = "essays.base/seed/"#
#
fcorpus = c( dir(seeddir, recursive=TRUE, full.names=TRUE) )#
length(fcorpus)#
#
fnessays = basename( c( dir(seeddir, recursive=TRUE)) )#
length(fnessays)#
#
gold = basename( dir(seeddir, recursive=TRUE) )#
fenc = NULL#
content = NULL#
umlauts = NULL#
output = NULL#
for (f in 1:length(fcorpus)) {#
    fn = fcorpus[f]#
    readStuff = NULL#
    tryCatch( {#
        fc = file(fn, encoding="iso-8859-1")#
        readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
        close(fc)#
    }, error=function(e) output = c(output, paste(f, ". error readLines ISO:",e,"\n", sep="")),#
    warning=function(e) output = c(output, paste(f, ". warning readLines ISO:",e,"\n", sep=""))#
    )#
    umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    if (!umlauts[f]) {#
        tryCatch( {#
            fc = file(fn, encoding="UTF8")#
            readStuff = paste( readLines(fc, warn=FALSE), collapse=" ")#
            close(fc)#
        }, error=function(e) output = c(output, paste(f, ". error readLines UTF8:",e,"\n", sep="")),#
        warning=function(e) output = c(output, paste(f, ". warning readLines UTF8:",e,"\n", sep="")))#
        umlauts[f] = grepl("[äöüÄÖÜß]", readStuff)#
    }#
    if (!umlauts[f]) output = c(output,paste(f, ". no umlauts after utf8\n", sep=""))#
    fenc[f] = Encoding(readStuff)#
    content[f] = readStuff#
}#
lost=which(!umlauts)#
thegolds = cbind(fnessays, content)#
#
ppl = HumanResourceManager(domainmanager=dmgr, domain=d)#
goldpers = ppl$add(name="goldstandards")#
#
for (i in 1:nrow(thegolds)) {#
    goldpers$perform( thegolds[i,2], activity="exam", purpose="exam")#
}#
#
mv = goldpers$getMeaningVectors()#
goldsdtm = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(mv))#
colnames(goldsdtm) = thegolds[,1]#
#
# mix with essays#
#
fulldtm = cbind(as.textmatrix(d$space), goldsdtm)#
e2e = lsa::cosine(fulldtm)#
#
rownames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
colnames(e2e)[1:nrow(d$space$dk)] = essays.content[-empty,1]#
#
e2e[1:10,1:10]#
#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
#
}
dim(goldsdtm)
meancos
goldsix
goldsix2
mv
goldsix
gold
mv
goldnameskey
rownames(e2e)
goldsix
nre = ncol(as.textmatrix(d$space))
nre
goldsix
nr
mv
goldmvs = mv[goldsix-nre,]
goldmvs
theix
theevecs = space$dk[theix,]
theix
dim(space$dk)
theevecs = space$dk[theix[which(theix<nre)],]
theevecs
rownames(theevecs) = rownames(space$dk)[ theix[which(theix<nre)] ]
theevecs
rownames(theevecs)
rownames(space$dk)
colnames(space$dk)
rownames(space$dk)
essays.content[-empty,1][theix[which(theix<nre)]]
rownames(theevecs) = essays.content[-empty,1][theix[which(theix<nre)]]
theevecs
goldmvs = mv[goldsix-nre,]#
    goldposition = colSums( mvecs ) / 3#
    goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))#
    goldtermixs = which(goldtermvec>d$proximityThreshold)#
    goldterms = rownames(goldtermvec[goldtermixs,])#
    theevecs = space$dk[theix[which(theix<nre)],]#
    rownames(theevecs) = essays.content[-empty,1][theix[which(theix<nre)]]#
    theetermvecs = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(theevecs))#
#
    goldoverlap = NULL#
    for (z in 1:nrow(theevecs)) {#
        essaytermsvec = theetermvecs[,z]#
        essaytermixs = which(essaytermsvec>d$proximityThreshold)#
        essayterms = rownames(essaytermvec[essaytermixs,])#
        allterms = c(goldterms, essayterms)#
        goldoverlap[z] = length( which( table(allterms) == 2 ) )#
    }
nre
goldsix
goldsix-nre
goldmvs = mv[goldsix-nre,]#
    goldposition = colSums( goldmvs ) / 3
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))#
    goldtermixs = which(goldtermvec>d$proximityThreshold)#
    goldterms = rownames(goldtermvec[goldtermixs,])
dim(space$dk)
dim(goldposition)
goldmvs
colSums(goldmvs)
colSums(goldmvs)/3
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(as.matrix(goldposition)))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), as.matrix(goldposition))
t(goldposition)
(goldposition)
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), (goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))
goldtermvec = crossprod((crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), as.matrix(goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(as.matrix(goldposition)))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(goldposition))
goldtermvec = crossprod(t(crossprod(t(space$tk), diag(space$sk))), (goldposition))
goldtermixs = which(goldtermvec>d$proximityThreshold)#
    goldterms = rownames(goldtermvec[goldtermixs,])
goldterms
goldtermixs
goldterms = rownames(space$tk[goldtermixs,])
goldterms
theevecs = space$dk[theix[which(theix<nre)],]#
    rownames(theevecs) = essays.content[-empty,1][theix[which(theix<nre)]]#
    theetermvecs = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), t(theevecs))
theetermvecs = crossprod(t(crossprod(t(space$tk), diag(domain$space$sk))), (theevecs))
theevecs
theetermvecs = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(theevecs))
theetermvecs
z = 1
goldoverlap = NULL
essaytermsvec = theetermvecs[,z]#
        essaytermixs = which(essaytermsvec>d$proximityThreshold)#
        essayterms = rownames(space$tk)[essaytermixs]
essayterms
allterms = c(goldterms, essayterms)#
        goldoverlap[z] = length( which( table(allterms) == 2 ) )
goldoverlap
table(allterms)
essayterms
goldterms
goldoverlap = NULL#
    for (z in 1:nrow(theevecs)) {#
        essaytermsvec = theetermvecs[,z]#
        essaytermixs = which(essaytermsvec>d$proximityThreshold)#
        essayterms = rownames(space$tk)[essaytermixs]#
        allterms = c(goldterms, essayterms)#
        goldoverlap[z] = length( which( table(allterms) == 2 ) )#
    }
goldoverlap
humanscores
humanscores
rownames(theevecs)
machinescores = goldoverlap#
    names(machinescores) = rownames(theevecs)
machinescores
print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )
nre = ncol(as.textmatrix(d$space))#
#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    #print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
    # calc by overlap#
    goldmvs = mv[goldsix-nre,]#
    goldposition = colSums( goldmvs ) / 3#
    goldtermvec = crossprod(t(crossprod(t(space$tk), diag(space$sk))), (goldposition))#
    goldtermixs = which(goldtermvec>d$proximityThreshold)#
    goldterms = rownames(space$tk[goldtermixs,])#
    theevecs = space$dk[theix[which(theix<nre)],]#
    rownames(theevecs) = essays.content[-empty,1][theix[which(theix<nre)]]#
    theetermvecs = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(theevecs))#
#
    goldoverlap = NULL#
    for (z in 1:nrow(theevecs)) {#
        essaytermsvec = theetermvecs[,z]#
        essaytermixs = which(essaytermsvec>d$proximityThreshold)#
        essayterms = rownames(space$tk)[essaytermixs]#
        allterms = c(goldterms, essayterms)#
        goldoverlap[z] = length( which( table(allterms) == 2 ) )#
    }#
    machinescores = goldoverlap#
    names(machinescores) = rownames(theevecs)#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
}
nr
cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided")
a = cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided")
a
a$rho
a$Rho
a$statistic
a = cor( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided")
a = cor( humanscores[names(machinescores),1], machinescores, method="spearman", alternative="two.sided")
a = cor( humanscores[names(machinescores),1], machinescores, method="spearman")
a
a = cor( humanscores[names(machinescores),1], machinescores, method="spearman")
rhos = rep(NULL,10)#
for (nr in c(1:3,5:10)) {#
    thekey = paste( "data",nr, "_", sep="")#
    theix = which( substr(rownames(e2e),1,nchar(thekey)) == thekey)#
    goldnameskey = paste( "data",nr, "_golden", sep="")#
    goldsix = which( substr(rownames(e2e),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = e2e[goldsix,theix]#
    goldsix2 = which( substr(colnames(meancos),1,nchar(goldnameskey)) == goldnameskey)#
    meancos = colSums( meancos[,-goldsix2] ) /3#
#
    humanscores = read.csv(paste("essays.scores/corpus.", nr, ".grades", sep=""), sep=" ", header=FALSE, row.names="V1")#
    machinescores = meancos#
    #print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
    # calc by overlap#
    goldmvs = mv[goldsix-nre,]#
    goldposition = colSums( goldmvs ) / 3#
    goldtermvec = crossprod(t(crossprod(t(space$tk), diag(space$sk))), (goldposition))#
    goldtermixs = which(goldtermvec>d$proximityThreshold)#
    goldterms = rownames(space$tk[goldtermixs,])#
    theevecs = space$dk[theix[which(theix<nre)],]#
    rownames(theevecs) = essays.content[-empty,1][theix[which(theix<nre)]]#
    theetermvecs = crossprod(t(crossprod(t(space$tk), diag(space$sk))), t(theevecs))#
#
    goldoverlap = NULL#
    for (z in 1:nrow(theevecs)) {#
        essaytermsvec = theetermvecs[,z]#
        essaytermixs = which(essaytermsvec>d$proximityThreshold)#
        essayterms = rownames(space$tk)[essaytermixs]#
        allterms = c(goldterms, essayterms)#
        goldoverlap[z] = length( which( table(allterms) == 2 ) )#
    }#
    machinescores = goldoverlap#
    names(machinescores) = rownames(theevecs)#
    print( cor.test( humanscores[names(machinescores),1], machinescores, exact=FALSE, method="spearman", alternative="two.sided") )#
    rhos[nr] =cor( humanscores[names(machinescores),1], machinescores, method="spearman")#
#
}
rhos
mean(rhos)
mean(rhos, remove.NA=TRUe)
?mean
mean(rhos, na.rm=T)
q()
q()
